# MUJICA: Multi-modal Unified Joint-learning for Industrial Collaborative Adaptation

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

---

**MUJICA** (Multi-modal Unified Joint-learning for Industrial Collaborative Adaptation)  
is a deployment-oriented research framework for **adaptive wearable safety systems**.  
It integrates **cross-task pretraining**, **active learning**, **modality robustness**.  

## Datasets

This project relies on two widely used public datasets:

- **[WESAD (Wearable Stress and Affect Detection)](https://archive.ics.uci.edu/dataset/465/wesad%2Bwearable%2Bstress%2Band%2Baffect%2Bdetection)**  
  A multimodal dataset with 17 subjects, including ECG, EDA, EMG, RESP, TEMP, and ACC signals,  
  recorded under baseline, stress, and amusement conditions.  
  Citation: Schmidt et al., 2018 (ACM ICMI).  

- **[REALDISP (Realistic Sensor Displacement Dataset)](https://archive.ics.uci.edu/dataset/305/realdisp+activity+recognition+dataset)**  
  A large-scale human activity dataset with 17 participants, including ACC, GYRO, and MAG signals across 33 activities, recorded with deliberate sensor displacement to simulate real-world wearable conditions.  
  Citation: Reyes-Ortiz et al., 2016 (*J. Ambient Intell. Smart Environ.*).
