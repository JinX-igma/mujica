# MUJICA: Multi-modal Unified Joint-learning for Industrial Collaborative Adaptation

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

---

**MUJICA** (Multi-modal Unified Joint-learning for Industrial Collaborative Adaptation)  
is a deployment-oriented research framework for **adaptive wearable safety systems**.  
It integrates **cross-task pretraining**, **active learning**, **modality robustness**.  

## Datasets

This project relies on two widely used public datasets:

- **[WESAD (Wearable Stress and Affect Detection)](https://doi.org/10.24432/C5TG7C)**  
  A multimodal dataset with 17 subjects, including ECG, EDA, EMG, RESP, TEMP, and ACC signals,  
  recorded under baseline, stress, and amusement conditions.  
  Citation: Schmidt et al., 2018 (ACM ICMI).  

- **[MHEALTH (Mobile Health Dataset)](https://archive.ics.uci.edu/dataset/319/mhealth+dataset)**  
  A mobile health dataset with 10 subjects, including ECG, accelerometer, gyroscope, and magnetometer signals,  
  covering a variety of physical activities and movements.  
  Citation: Banos et al., 2014 (Journal of Biomedical Informatics).  
